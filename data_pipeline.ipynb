{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline is as follows:\n",
    "\n",
    "Download the city gml files -> Convert to shapefiles -> Divide into grids -> Calculate UMP for each grid -> Save as y\n",
    "\n",
    "Loop through each grid, download sentinel imagery, store and write as tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X:\n",
    "    - Sentinel\n",
    "- Y:\n",
    "    - Tokyo (Japan, 2021) https://www.geospatial.jp/ckan/dataset/plateau-tokyo23ku/resource/0bab2b7f-6962-41c8-872f-66ad9b40dcb1?inner_span=True\n",
    "    - Osaka (Japan, 2021) ^ \n",
    "    - New York (USA, 2019) https://github.com/opencitymodel/opencitymodel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import fiona\n",
    "from fiona import errors\n",
    "from fiona import _err\n",
    "import os.path\n",
    "# import mpi4py.MPI as mpi\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import pyproj\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert GML to shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all of the GML files in a folder into a single shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gml_to_feather(in_path, out_path, mode= \"a\", log_name= \"gml_convert\", src_crs= \"EPSG:6668\", tgt_src= \"EPSG:3857\"):\n",
    "    \"\"\"\n",
    "    Takes in a gml file and outputs it as a feather file\\n\n",
    "    W/R with feather files is much faster and takes up much less space than using shp files\\n\n",
    "    # Parameters:\\n\n",
    "    - in_path: The path for the gml file\\n\n",
    "    - out_path: The output path for the shape file, must end with a .shp\\n\n",
    "    - mode: \n",
    "        - 'a' = appends to the out_path shapefile if any, \\n\n",
    "        - 'o' = overwrites any file at output path, \\n\n",
    "        - None = raises error if file already exists\\n\n",
    "    - src_crs: Source projection\\n\n",
    "    - tgt_src: Target projection\\n\n",
    "    \"\"\"\n",
    "    # Extracts features\n",
    "    with fiona.open(in_path, 'r') as src:\n",
    "        features = list(src)\n",
    "\n",
    "    # Converts and places it in geopandas format\n",
    "    # There seems to be some gml files without the measured height column, will try to log those files in\n",
    "    gdf = gpd.GeoDataFrame.from_features(features)\n",
    "    try:\n",
    "        gdf = gdf[['measuredHeight', 'geometry']]\n",
    "        gdf.rename(columns={'measuredHeight':'height'}, inplace= True)\n",
    "    except Exception as e:\n",
    "        print(f\"{e}: {os.path.basename(in_path)}\")\n",
    "        if not os.path.exists(\"logs\"):\n",
    "            os.makedirs(\"logs\")\n",
    "        with open(f\"logs/{log_name}.txt\", \"a\") as f:\n",
    "            f.write(in_path + \"\\n\")\n",
    "        return len(gdf)\n",
    "\n",
    "    # Remove the NaN values\n",
    "    gdf = gdf.dropna().reset_index(drop= True)\n",
    "\n",
    "    # Covert it to correct projection and strip to polygon instead from multi polygon\n",
    "\n",
    "    # There is key error with somehow, plus most of the shapes are negligible, hence we will only be taking the first one\n",
    "    try:\n",
    "        gdf = gdf.explode(index_parts= True).set_crs(src_crs).to_crs(tgt_src).loc[(slice(None), slice(0)), :].reset_index(drop= True)\n",
    "    except Exception as e:\n",
    "        print(f\"{e}: {os.path.basename(in_path)}\")\n",
    "        if not os.path.exists(\"logs\"):\n",
    "            os.makedirs(\"logs\")\n",
    "        with open(f\"logs/{log_name}.txt\", \"a\") as f:\n",
    "            f.write(in_path + \"\\n\")\n",
    "        return len(gdf)\n",
    "\n",
    "\n",
    "    # Convert coordinates from 2D to 3D\n",
    "    gdf_geometry = gpd.GeoSeries.from_wkb(gdf.to_wkb(output_dimension= 2)[\"geometry\"])\n",
    "    gdf.drop([\"geometry\"], axis= 1, inplace= True)\n",
    "    gdf = gpd.GeoDataFrame(gdf, geometry= gdf_geometry)\n",
    "\n",
    "    # Check if parent directory exists\n",
    "    if not os.path.exists(os.path.dirname(out_path)):\n",
    "        os.makedirs(os.path.dirname(out_path))\n",
    "        \n",
    "    # Outputs to the desired path\n",
    "    if os.path.exists(out_path):\n",
    "        if mode == \"a\":\n",
    "            gdf.to_feather(out_path, mode= \"a\")\n",
    "        elif mode == \"o\":\n",
    "            gdf.to_feather(out_path)\n",
    "        else:\n",
    "            raise FileExistsError(\"Output path already exists\")\n",
    "    else:\n",
    "        gdf.to_feather(out_path)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 671\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392642_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392641_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392633_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53393631_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392663_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392653_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53393671_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392651_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392662_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53393683_bldg_6697_2_op.gml\n",
      "\"None of [Index(['measuredHeight', 'geometry'], dtype='object')] are in the [columns]\": 53394525_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392652_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53393672_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53393599_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392643_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392672_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53394601_bldg_6697_2_op.gml\n",
      "There are 3654 invalid buildings from 671 files\n",
      "Total: 654\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1</td>\n",
       "      <td>POLYGON ((15565422.798 4245286.909, 15565416.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>POLYGON ((15565401.386 4245273.087, 15565398.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>POLYGON ((15563817.297 4264833.695, 15563811.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.8</td>\n",
       "      <td>POLYGON ((15563065.418 4265104.495, 15563064.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>POLYGON ((15563458.540 4264729.005, 15563431.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>8.1</td>\n",
       "      <td>POLYGON ((15547325.623 4251960.079, 15547330.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>POLYGON ((15547878.824 4251983.939, 15547872.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5101</th>\n",
       "      <td>8.2</td>\n",
       "      <td>POLYGON ((15548373.420 4252264.298, 15548372.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5102</th>\n",
       "      <td>12.6</td>\n",
       "      <td>POLYGON ((15548263.540 4251615.712, 15548262.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5103</th>\n",
       "      <td>10.0</td>\n",
       "      <td>POLYGON ((15547241.958 4251864.072, 15547241.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1735753 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      height                                           geometry\n",
       "0        6.1  POLYGON ((15565422.798 4245286.909, 15565416.2...\n",
       "1        3.0  POLYGON ((15565401.386 4245273.087, 15565398.9...\n",
       "0        3.5  POLYGON ((15563817.297 4264833.695, 15563811.6...\n",
       "1       11.8  POLYGON ((15563065.418 4265104.495, 15563064.8...\n",
       "2        2.5  POLYGON ((15563458.540 4264729.005, 15563431.3...\n",
       "...      ...                                                ...\n",
       "5099     8.1  POLYGON ((15547325.623 4251960.079, 15547330.5...\n",
       "5100     6.3  POLYGON ((15547878.824 4251983.939, 15547872.9...\n",
       "5101     8.2  POLYGON ((15548373.420 4252264.298, 15548372.5...\n",
       "5102    12.6  POLYGON ((15548263.540 4251615.712, 15548262.3...\n",
       "5103    10.0  POLYGON ((15547241.958 4251864.072, 15547241.3...\n",
       "\n",
       "[1735753 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_dir = \"data/13100_tokyo23-ku_2020_citygml_3_2_op/udx/bldg\"\n",
    "out_path = \"data/full_Tokyo_plateau/tokyo_full.feather\"\n",
    "\n",
    "# Get all the paths of the gml files\n",
    "in_paths = glob(f\"{in_dir}/*.gml\")\n",
    "print(\"Total:\", len(in_paths))\n",
    "\n",
    "# Reads the gml file and extract features\n",
    "with Pool(processes= 12) as pool:\n",
    "    r = pool.starmap(\n",
    "        gml_to_feather, \n",
    "        zip(in_paths, \n",
    "            [f'{in_dir}/temp/{os.path.basename(path).replace(\".gml\", \".feather\")}' for path in in_paths], \n",
    "            repeat(\"o\"), \n",
    "            repeat(\"osaka\")))\n",
    "\n",
    "# Check for invalid buildings\n",
    "print(f\"There are {sum(r)} invalid buildings from {len(list(filter(lambda x: x > 0, r)))} files\")\n",
    "\n",
    "# Get all the paths of the shp files\n",
    "in_paths = glob(f\"{in_dir}/temp/*.feather\")\n",
    "print(\"Total:\", len(in_paths))\n",
    "\n",
    "gdfs = [gpd.read_feather(in_path) for in_path in in_paths]\n",
    "gdf = gpd.GeoDataFrame(pd.concat(gdfs))\n",
    "gdf.to_feather(out_path)\n",
    "\n",
    "for temp_file in in_paths:\n",
    "    os.remove(temp_file)\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Osaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 269\n",
      "\"['measuredHeight'] not in index\": 51357370_bldg_6697_op.gml\n",
      "\"['measuredHeight'] not in index\": 52350389_bldg_6697_op.gml\n",
      "\"['measuredHeight'] not in index\": 52350378_bldg_6697_op.gml\n",
      "\"['measuredHeight'] not in index\": 52350379_bldg_6697_op.gml\n",
      "\"['measuredHeight'] not in index\": 52350368_bldg_6697_op.gml\n",
      "\"['measuredHeight'] not in index\": 52350422_bldg_6697_op.gml\n",
      "\"['measuredHeight'] not in index\": 52350480_bldg_6697_op.gml\n",
      "\"['measuredHeight'] not in index\": 52350470_bldg_6697_op.gml\n",
      "There are 12 invalid buildings from 269 files\n",
      "Total: 261\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.4</td>\n",
       "      <td>POLYGON ((15072751.097 4117217.254, 15072744.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.2</td>\n",
       "      <td>POLYGON ((15072760.795 4117204.681, 15072751.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.5</td>\n",
       "      <td>POLYGON ((15072609.643 4114039.178, 15072607.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.2</td>\n",
       "      <td>POLYGON ((15072558.583 4113986.948, 15072558.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.3</td>\n",
       "      <td>POLYGON ((15072645.993 4114000.366, 15072628.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>9.3</td>\n",
       "      <td>POLYGON ((15091759.769 4123301.748, 15091758.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>10.1</td>\n",
       "      <td>POLYGON ((15091667.204 4123479.427, 15091662.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3050</th>\n",
       "      <td>8.7</td>\n",
       "      <td>POLYGON ((15090879.355 4123787.077, 15090879.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>6.3</td>\n",
       "      <td>POLYGON ((15091797.642 4123827.310, 15091773.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>6.7</td>\n",
       "      <td>POLYGON ((15090792.241 4123322.324, 15090792.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>544280 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      height                                           geometry\n",
       "0        4.4  POLYGON ((15072751.097 4117217.254, 15072744.0...\n",
       "1        5.2  POLYGON ((15072760.795 4117204.681, 15072751.4...\n",
       "0       11.5  POLYGON ((15072609.643 4114039.178, 15072607.8...\n",
       "1        6.2  POLYGON ((15072558.583 4113986.948, 15072558.0...\n",
       "2        6.3  POLYGON ((15072645.993 4114000.366, 15072628.9...\n",
       "...      ...                                                ...\n",
       "3048     9.3  POLYGON ((15091759.769 4123301.748, 15091758.7...\n",
       "3049    10.1  POLYGON ((15091667.204 4123479.427, 15091662.0...\n",
       "3050     8.7  POLYGON ((15090879.355 4123787.077, 15090879.0...\n",
       "3051     6.3  POLYGON ((15091797.642 4123827.310, 15091773.6...\n",
       "3052     6.7  POLYGON ((15090792.241 4123322.324, 15090792.6...\n",
       "\n",
       "[544280 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_dir = \"data/osaka/udx/bldg\"\n",
    "out_path = \"data/osaka/osaka_full.feather\"\n",
    "\n",
    "# Get all the paths of the gml files\n",
    "in_paths = glob(f\"{in_dir}/*.gml\")\n",
    "print(\"Total:\", len(in_paths))\n",
    "\n",
    "# Reads the gml file and extract features\n",
    "with Pool(processes= 12) as pool:\n",
    "    r = pool.starmap(\n",
    "        gml_to_feather, \n",
    "        zip(in_paths, \n",
    "            [f'{in_dir}/temp/{os.path.basename(path).replace(\".gml\", \".feather\")}' for path in in_paths], \n",
    "            repeat(\"o\"), \n",
    "            repeat(\"osaka\")))\n",
    "\n",
    "# Check for invalid buildings\n",
    "print(f\"There are {sum(r)} invalid buildings from {len(list(filter(lambda x: x > 0, r)))} files\")\n",
    "\n",
    "# Get all the paths of the shp files\n",
    "in_paths = glob(f\"{in_dir}/temp/*.feather\")\n",
    "print(\"Total:\", len(in_paths))\n",
    "\n",
    "gdfs = [gpd.read_feather(in_path) for in_path in in_paths]\n",
    "gdf = gpd.GeoDataFrame(pd.concat(gdfs))\n",
    "gdf.to_feather(out_path)\n",
    "\n",
    "for temp_file in in_paths:\n",
    "    os.remove(temp_file)\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 170\n"
     ]
    }
   ],
   "source": [
    "in_dir = \"data/NewYork_2\"\n",
    "out_path = \"data/NewYork_2/new_york.feather\"\n",
    "src_crs = \"EPSG:4326\"\n",
    "\n",
    "# Get all the paths of the gml files\n",
    "in_paths = glob(f\"{in_dir}/*.gml\")\n",
    "print(\"Total:\", len(in_paths))\n",
    "\n",
    "# Reads the gml file and extract features\n",
    "with Pool(processes= 12) as pool:\n",
    "    r = pool.starmap(\n",
    "        gml_to_feather, \n",
    "        zip(in_paths, \n",
    "            [f'{in_dir}/temp/{os.path.basename(path).replace(\".gml\", \".feather\")}' for path in in_paths], \n",
    "            repeat(\"o\"), \n",
    "            repeat(\"NewYork\"),\n",
    "            repeat(src_crs)))\n",
    "\n",
    "# Check for invalid buildings\n",
    "print(f\"There are {sum(r)} invalid buildings from {len(list(filter(lambda x: x > 0, r)))} files\")\n",
    "\n",
    "# Get all the paths of the shp files\n",
    "in_paths = glob(f\"{in_dir}/temp/*.feather\")\n",
    "print(\"Total:\", len(in_paths))\n",
    "\n",
    "gdfs = [gpd.read_feather(in_path) for in_path in in_paths]\n",
    "gdf = gpd.GeoDataFrame(pd.concat(gdfs))\n",
    "gdf.to_feather(out_path)\n",
    "\n",
    "for temp_file in in_paths:\n",
    "    os.remove(temp_file)\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate UMP and export as y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Sentinel and export as X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8bf42f5b4e2a348cbe75a25ff6042248da5e17de0cf2c8b06b72f8092ad4452"
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('remote-sensing-landuse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
