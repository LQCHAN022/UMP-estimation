{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline is as follows:\n",
    "\n",
    "Download the city gml files -> Convert to shapefiles -> Divide into grids -> Calculate UMP for each grid -> Save as y\n",
    "\n",
    "Loop through each grid, download sentinel imagery, store and write as tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X:\n",
    "    - Sentinel\n",
    "- Y:\n",
    "    - Tokyo (Japan, 2021) https://www.geospatial.jp/ckan/dataset/plateau-tokyo23ku/resource/0bab2b7f-6962-41c8-872f-66ad9b40dcb1?inner_span=True\n",
    "    - Osaka (Japan, 2021) ^ \n",
    "    - New York (USA, 2019) https://github.com/opencitymodel/opencitymodel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import fiona\n",
    "from fiona import errors\n",
    "from fiona import _err\n",
    "import os.path\n",
    "# import mpi4py.MPI as mpi\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import pyproj\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert GML to shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all of the GML files in a folder into a single shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gml_to_feather(in_path, out_path, mode= \"a\", log_name= \"gml_convert\", src_crs= \"EPSG:6668\", tgt_src= \"EPSG:3857\"):\n",
    "    \"\"\"\n",
    "    Takes in a gml file and outputs it as a feather file\\n\n",
    "    W/R with feather files is much faster and takes up much less space than using shp files\\n\n",
    "    # Parameters:\\n\n",
    "    - in_path: The path for the gml file\\n\n",
    "    - out_path: The output path for the shape file, must end with a .shp\\n\n",
    "    - mode: \n",
    "        - 'a' = appends to the out_path shapefile if any, \\n\n",
    "        - 'o' = overwrites any file at output path, \\n\n",
    "        - None = raises error if file already exists\\n\n",
    "    - src_crs: Source projection\\n\n",
    "    - tgt_src: Target projection\\n\n",
    "    \"\"\"\n",
    "    # Extracts features\n",
    "    with fiona.open(in_path, 'r') as src:\n",
    "        features = list(src)\n",
    "\n",
    "    # Converts and places it in geopandas format\n",
    "    # There seems to be some gml files without the measured height column, will try to log those files in\n",
    "    gdf = gpd.GeoDataFrame.from_features(features)\n",
    "    try:\n",
    "        gdf = gdf[['measuredHeight', 'geometry']]\n",
    "        gdf.rename(columns={'measuredHeight':'height'}, inplace= True)\n",
    "    except Exception as e:\n",
    "        print(f\"{e}: {os.path.basename(in_path)}\")\n",
    "        if not os.path.exists(\"logs\"):\n",
    "            os.makedirs(\"logs\")\n",
    "        with open(f\"logs/{log_name}.txt\", \"a\") as f:\n",
    "            f.write(in_path + \"\\n\")\n",
    "        return len(gdf)\n",
    "\n",
    "    # Remove the NaN values\n",
    "    gdf = gdf.dropna().reset_index(drop= True)\n",
    "\n",
    "    # Covert it to correct projection and strip to polygon instead from multi polygon\n",
    "\n",
    "    # There is key error with somehow, plus most of the shapes are negligible, hence we will only be taking the first one\n",
    "    try:\n",
    "        gdf = gdf.explode(index_parts= True).set_crs(src_crs).to_crs(tgt_src).loc[(slice(None), slice(0)), :].reset_index(drop= True)\n",
    "    except Exception as e:\n",
    "        print(f\"{e}: {os.path.basename(in_path)}\")\n",
    "        if not os.path.exists(\"logs\"):\n",
    "            os.makedirs(\"logs\")\n",
    "        with open(f\"logs/{log_name}.txt\", \"a\") as f:\n",
    "            f.write(in_path + \"\\n\")\n",
    "        return len(gdf)\n",
    "\n",
    "\n",
    "    # Convert coordinates from 2D to 3D\n",
    "    gdf_geometry = gpd.GeoSeries.from_wkb(gdf.to_wkb(output_dimension= 2)[\"geometry\"])\n",
    "    gdf.drop([\"geometry\"], axis= 1, inplace= True)\n",
    "    gdf = gpd.GeoDataFrame(gdf, geometry= gdf_geometry)\n",
    "\n",
    "    # Check if parent directory exists\n",
    "    if not os.path.exists(os.path.dirname(out_path)):\n",
    "        os.makedirs(os.path.dirname(out_path))\n",
    "        \n",
    "    # Outputs to the desired path\n",
    "    if os.path.exists(out_path):\n",
    "        if mode == \"a\":\n",
    "            gdf.to_feather(out_path, mode= \"a\")\n",
    "        elif mode == \"o\":\n",
    "            gdf.to_feather(out_path)\n",
    "        else:\n",
    "            raise FileExistsError(\"Output path already exists\")\n",
    "    else:\n",
    "        gdf.to_feather(out_path)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 671\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392642_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392641_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392633_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53393631_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392663_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392653_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53393671_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392651_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392662_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53393683_bldg_6697_2_op.gml\n",
      "\"None of [Index(['measuredHeight', 'geometry'], dtype='object')] are in the [columns]\": 53394525_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392652_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53393672_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53393599_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392643_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392672_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53394601_bldg_6697_2_op.gml\n"
     ]
    }
   ],
   "source": [
    "in_dir = \"data/13100_tokyo23-ku_2020_citygml_3_2_op/udx/bldg\"\n",
    "out_path = \"data/full_Tokyo_plateau/tokyo_full.feather\"\n",
    "\n",
    "# Get all the paths of the gml files\n",
    "in_paths = glob(f\"{in_dir}/*.gml\")\n",
    "print(\"Total:\", len(in_paths))\n",
    "\n",
    "# Reads the gml file and extract features\n",
    "with Pool(processes= 12) as pool:\n",
    "    r = pool.starmap(\n",
    "        gml_to_feather, \n",
    "        zip(in_paths, \n",
    "            [f'{in_dir}/temp/{os.path.basename(path).replace(\".gml\", \".feather\")}' for path in in_paths], \n",
    "            repeat(\"o\"), \n",
    "            repeat(\"osaka\")))\n",
    "\n",
    "# Check for invalid buildings\n",
    "print(f\"There are {sum(r)} invalid buildings from {len(r)} files\")\n",
    "\n",
    "# Get all the paths of the shp files\n",
    "in_paths = glob(f\"{in_dir}/temp/*.feather\")\n",
    "print(\"Total:\", len(in_paths))\n",
    "\n",
    "gdfs = [gpd.read_feather(in_path) for in_path in in_paths]\n",
    "gdf = gpd.GeoDataFrame(pd.concat(gdfs))\n",
    "gdf.to_feather(out_path)\n",
    "\n",
    "for temp_file in in_paths:\n",
    "    os.remove(temp_file)\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Osaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 269\n",
      "\"['measuredHeight'] not in index\": 51357370_bldg_6697_op.gml\n",
      "\"['measuredHeight'] not in index\": 52350389_bldg_6697_op.gml\n",
      "\"['measuredHeight'] not in index\": 52350378_bldg_6697_op.gml\n",
      "\"['measuredHeight'] not in index\": 52350379_bldg_6697_op.gml\n",
      "\"['measuredHeight'] not in index\": 52350368_bldg_6697_op.gml\n",
      "\"['measuredHeight'] not in index\": 52350422_bldg_6697_op.gml\n",
      "\"['measuredHeight'] not in index\": 52350480_bldg_6697_op.gml\n",
      "\"['measuredHeight'] not in index\": 52350470_bldg_6697_op.gml\n",
      "Total: 261\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.4</td>\n",
       "      <td>POLYGON ((15072751.097 4117217.254, 15072744.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.2</td>\n",
       "      <td>POLYGON ((15072760.795 4117204.681, 15072751.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.5</td>\n",
       "      <td>POLYGON ((15072609.643 4114039.178, 15072607.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.2</td>\n",
       "      <td>POLYGON ((15072558.583 4113986.948, 15072558.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.3</td>\n",
       "      <td>POLYGON ((15072645.993 4114000.366, 15072628.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>9.0</td>\n",
       "      <td>POLYGON ((15089601.610 4130609.416, 15089594.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>9.1</td>\n",
       "      <td>POLYGON ((15089727.284 4130200.798, 15089723.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>5.6</td>\n",
       "      <td>POLYGON ((15089513.115 4130506.862, 15089518.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>8.9</td>\n",
       "      <td>POLYGON ((15089905.222 4130629.136, 15089897.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>9.3</td>\n",
       "      <td>POLYGON ((15089745.087 4130299.201, 15089744.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>544280 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     height                                           geometry\n",
       "0       4.4  POLYGON ((15072751.097 4117217.254, 15072744.0...\n",
       "1       5.2  POLYGON ((15072760.795 4117204.681, 15072751.4...\n",
       "0      11.5  POLYGON ((15072609.643 4114039.178, 15072607.8...\n",
       "1       6.2  POLYGON ((15072558.583 4113986.948, 15072558.0...\n",
       "2       6.3  POLYGON ((15072645.993 4114000.366, 15072628.9...\n",
       "..      ...                                                ...\n",
       "926     9.0  POLYGON ((15089601.610 4130609.416, 15089594.1...\n",
       "927     9.1  POLYGON ((15089727.284 4130200.798, 15089723.3...\n",
       "928     5.6  POLYGON ((15089513.115 4130506.862, 15089518.6...\n",
       "929     8.9  POLYGON ((15089905.222 4130629.136, 15089897.1...\n",
       "930     9.3  POLYGON ((15089745.087 4130299.201, 15089744.4...\n",
       "\n",
       "[544280 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_dir = \"data/osaka/udx/bldg\"\n",
    "out_path = \"data/osaka/osaka_full.feather\"\n",
    "\n",
    "# Get all the paths of the gml files\n",
    "in_paths = glob(f\"{in_dir}/*.gml\")\n",
    "print(\"Total:\", len(in_paths))\n",
    "\n",
    "# Reads the gml file and extract features\n",
    "with Pool(processes= 12) as pool:\n",
    "    r = pool.starmap(\n",
    "        gml_to_feather, \n",
    "        zip(in_paths, \n",
    "            [f'{in_dir}/temp/{os.path.basename(path).replace(\".gml\", \".feather\")}' for path in in_paths], \n",
    "            repeat(\"o\"), \n",
    "            repeat(\"osaka\")))\n",
    "\n",
    "# Check for invalid buildings\n",
    "print(f\"There are {sum(r)} invalid buildings from {len(r)} files\")\n",
    "\n",
    "# Get all the paths of the shp files\n",
    "in_paths = glob(f\"{in_dir}/temp/*.feather\")\n",
    "print(\"Total:\", len(in_paths))\n",
    "\n",
    "gdfs = [gpd.read_feather(in_path) for in_path in in_paths]\n",
    "gdf = gpd.GeoDataFrame(pd.concat(gdfs))\n",
    "gdf.to_feather(out_path)\n",
    "\n",
    "for temp_file in in_paths:\n",
    "    os.remove(temp_file)\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 170\n",
      "Total: 170\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.73</td>\n",
       "      <td>POLYGON ((-8209085.418 5566790.279, -8209067.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.73</td>\n",
       "      <td>POLYGON ((-8209070.390 5566764.459, -8209066.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.38</td>\n",
       "      <td>POLYGON ((-8209005.825 5566671.511, -8208999.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.73</td>\n",
       "      <td>POLYGON ((-8209225.236 5566628.949, -8209213.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.73</td>\n",
       "      <td>POLYGON ((-8209101.448 5566623.003, -8209085.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>4.38</td>\n",
       "      <td>POLYGON ((-8215328.048 5027787.294, -8215324.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>4.74</td>\n",
       "      <td>POLYGON ((-8215264.930 5027796.217, -8215262.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>5.17</td>\n",
       "      <td>POLYGON ((-8215139.829 5027478.327, -8215138.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>5.45</td>\n",
       "      <td>POLYGON ((-8215386.792 5027729.412, -8215384.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>5.71</td>\n",
       "      <td>POLYGON ((-8215318.965 5027747.125, -8215316.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5716439 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       height                                           geometry\n",
       "0        5.73  POLYGON ((-8209085.418 5566790.279, -8209067.0...\n",
       "1        5.73  POLYGON ((-8209070.390 5566764.459, -8209066.2...\n",
       "2        4.38  POLYGON ((-8209005.825 5566671.511, -8208999.0...\n",
       "3        5.73  POLYGON ((-8209225.236 5566628.949, -8209213.3...\n",
       "4        5.73  POLYGON ((-8209101.448 5566623.003, -8209085.8...\n",
       "...       ...                                                ...\n",
       "14994    4.38  POLYGON ((-8215328.048 5027787.294, -8215324.3...\n",
       "14995    4.74  POLYGON ((-8215264.930 5027796.217, -8215262.7...\n",
       "14996    5.17  POLYGON ((-8215139.829 5027478.327, -8215138.1...\n",
       "14997    5.45  POLYGON ((-8215386.792 5027729.412, -8215384.6...\n",
       "14998    5.71  POLYGON ((-8215318.965 5027747.125, -8215316.0...\n",
       "\n",
       "[5716439 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_dir = \"data/NewYork_2\"\n",
    "out_path = \"data/NewYork_2/new_york.feather\"\n",
    "src_crs = \"EPSG:4326\"\n",
    "\n",
    "# Get all the paths of the gml files\n",
    "in_paths = glob(f\"{in_dir}/*.gml\")\n",
    "print(\"Total:\", len(in_paths))\n",
    "\n",
    "# Reads the gml file and extract features\n",
    "with Pool(processes= 12) as pool:\n",
    "    r = pool.starmap(\n",
    "        gml_to_feather, \n",
    "        zip(in_paths, \n",
    "            [f'{in_dir}/temp/{os.path.basename(path).replace(\".gml\", \".feather\")}' for path in in_paths], \n",
    "            repeat(\"o\"), \n",
    "            repeat(\"NewYork\"),\n",
    "            repeat(src_crs)))\n",
    "\n",
    "# Check for invalid buildings\n",
    "print(f\"There are {sum(r)} invalid buildings from {len(r)} files\")\n",
    "\n",
    "# Get all the paths of the shp files\n",
    "in_paths = glob(f\"{in_dir}/temp/*.feather\")\n",
    "print(\"Total:\", len(in_paths))\n",
    "\n",
    "gdfs = [gpd.read_feather(in_path) for in_path in in_paths]\n",
    "gdf = gpd.GeoDataFrame(pd.concat(gdfs))\n",
    "gdf.to_feather(out_path)\n",
    "\n",
    "for temp_file in in_paths:\n",
    "    os.remove(temp_file)\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate UMP and export as y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Sentinel and export as X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8bf42f5b4e2a348cbe75a25ff6042248da5e17de0cf2c8b06b72f8092ad4452"
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('remote-sensing-landuse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
