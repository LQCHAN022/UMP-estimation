{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline is as follows:\n",
    "\n",
    "Download the city gml files -> Convert to shapefiles -> Divide into grids -> Calculate UMP for each grid -> Save as y\n",
    "\n",
    "Loop through each grid, download sentinel imagery, store and write as tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X:\n",
    "    - Sentinel\n",
    "- Y:\n",
    "    - Tokyo (Japan, 2021) https://www.geospatial.jp/ckan/dataset/plateau-tokyo23ku/resource/0bab2b7f-6962-41c8-872f-66ad9b40dcb1?inner_span=True\n",
    "    - Osaka (Japan, 2021) ^ \n",
    "    - New York (USA, 2019) https://github.com/opencitymodel/opencitymodel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import fiona\n",
    "import os.path\n",
    "from multiprocessing import Pool\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert GML to shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all of the GML files in a folder into a single shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gml_to_feather(in_path, out_path, mode= None, log_name= \"gml_convert\", src_crs= \"EPSG:6668\", tgt_src= \"EPSG:3857\"):\n",
    "    \"\"\"\n",
    "    Takes in a gml file and outputs it as a feather file\\n\n",
    "    W/R with feather files is much faster and takes up much less space than using shp files\\n\n",
    "    # Parameters:\\n\n",
    "    - in_path: The path for the gml file\\n\n",
    "    - out_path: The output path for the shape file, must end with a .shp\\n\n",
    "    - mode: \n",
    "        - 'o' = overwrites any file at output path, \\n\n",
    "        - None = raises error if file already exists\\n\n",
    "    - src_crs: Source projection\\n\n",
    "    - tgt_src: Target projection\\n\n",
    "    \"\"\"\n",
    "    # Extracts features\n",
    "    with fiona.open(in_path, 'r') as src:\n",
    "        features = list(src)\n",
    "\n",
    "    # Converts and places it in geopandas format\n",
    "    # There seems to be some gml files without the measured height column, will try to log those files in\n",
    "    gdf = gpd.GeoDataFrame.from_features(features)\n",
    "    try:\n",
    "        gdf = gdf[['measuredHeight', 'geometry']]\n",
    "        gdf.rename(columns={'measuredHeight':'height'}, inplace= True)\n",
    "    except Exception as e:\n",
    "        print(f\"{e}: {os.path.basename(in_path)}\")\n",
    "        if not log_name is None:\n",
    "            if not os.path.exists(\"logs\"):\n",
    "                os.makedirs(\"logs\")\n",
    "            with open(f\"logs/{log_name}.txt\", \"a\") as f:\n",
    "                f.write(in_path + \"\\n\")\n",
    "        return len(gdf)\n",
    "\n",
    "    # Remove the NaN values\n",
    "    gdf = gdf.dropna().reset_index(drop= True)\n",
    "\n",
    "    # Covert it to correct projection and strip to polygon instead from multi polygon\n",
    "\n",
    "    # There is key error with somehow, plus most of the shapes are negligible, hence we will only be taking the first one\n",
    "    try:\n",
    "        gdf = gdf.explode(index_parts= True).set_crs(src_crs).to_crs(tgt_src).loc[(slice(None), slice(0)), :].reset_index(drop= True)\n",
    "    except Exception as e:\n",
    "        print(f\"{e}: {os.path.basename(in_path)}\")\n",
    "        if not log_name is None:\n",
    "            if not os.path.exists(\"logs\"):\n",
    "                os.makedirs(\"logs\")\n",
    "            with open(f\"logs/{log_name}.txt\", \"a\") as f:\n",
    "                f.write(in_path + \"\\n\")\n",
    "        return len(gdf)\n",
    "\n",
    "\n",
    "    # Convert coordinates from 2D to 3D\n",
    "    gdf_geometry = gpd.GeoSeries.from_wkb(gdf.to_wkb(output_dimension= 2)[\"geometry\"])\n",
    "    gdf.drop([\"geometry\"], axis= 1, inplace= True)\n",
    "    gdf = gpd.GeoDataFrame(gdf, geometry= gdf_geometry)\n",
    "\n",
    "    # Check if parent directory exists\n",
    "    if not os.path.exists(os.path.dirname(out_path)):\n",
    "        os.makedirs(os.path.dirname(out_path))\n",
    "        \n",
    "    # Outputs to the desired path\n",
    "    if os.path.exists(out_path):\n",
    "        if mode == \"a\":\n",
    "            gdf.to_feather(out_path, mode= \"a\")\n",
    "        elif mode == \"o\":\n",
    "            gdf.to_feather(out_path)\n",
    "        else:\n",
    "            raise FileExistsError(\"Output path already exists\")\n",
    "    else:\n",
    "        gdf.to_feather(out_path)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def batch_gml_to_feather(in_dir, out_path, n_processes= 12, log_name= None, mode= None, src_crs= \"EPSG:6668\", tgt_src= \"EPSG:3857\"):\n",
    "\n",
    "    # Get all the paths of the gml files\n",
    "    in_paths = glob(f\"{in_dir}/*.gml\")\n",
    "    print(\"Total input files:\", len(in_paths))\n",
    "\n",
    "    # Reads the gml file and extract features\n",
    "    with Pool(processes= n_processes) as pool:\n",
    "        r = pool.starmap(\n",
    "            gml_to_feather, \n",
    "            zip(in_paths, \n",
    "                [f'{in_dir}/temp/{os.path.basename(path).replace(\".gml\", \".feather\")}' for path in in_paths], \n",
    "                repeat(mode), \n",
    "                repeat(log_name),\n",
    "                repeat(src_crs),\n",
    "                repeat(tgt_src)))\n",
    "\n",
    "    # Check for invalid buildings\n",
    "    print(f\"There are {sum(r)} invalid buildings from {len(list(filter(lambda x: x > 0, r)))} files\")\n",
    "\n",
    "    # Get all the paths of the shp files\n",
    "    in_paths = glob(f\"{in_dir}/temp/*.feather\")\n",
    "    print(\"Total files to merge:\", len(in_paths))\n",
    "\n",
    "    gdfs = [gpd.read_feather(in_path) for in_path in in_paths]\n",
    "    gdf = gpd.GeoDataFrame(pd.concat(gdfs)).reset_index(drop= True)\n",
    "    gdf.to_feather(out_path)\n",
    "\n",
    "    for temp_file in in_paths:\n",
    "        os.remove(temp_file)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input files: 671\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392642_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392641_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392633_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53393631_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392663_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392653_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53393671_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392651_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53392662_bldg_6697_2_op.gml\n",
      "cannot do slice indexing on Index with these indexers [0] of type int: 53393683_bldg_6697_2_op.gml\n"
     ]
    }
   ],
   "source": [
    "in_dir = \"data/13100_tokyo23-ku_2020_citygml_3_2_op/udx/bldg\"\n",
    "out_path = \"data/full_Tokyo_plateau/tokyo_full.feather\"\n",
    "\n",
    "batch_gml_to_feather(in_dir, out_path, mode= \"o\", log_name= \"tokyo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Osaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input files: 269\n",
      "\"['measuredHeight'] not in index\": 51357370_bldg_6697_op.gml\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m in_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/osaka/udx/bldg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m out_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/osaka/osaka_full.feather\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mbatch_gml_to_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mosaka\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 81\u001b[0m, in \u001b[0;36mbatch_gml_to_feather\u001b[0;34m(in_dir, out_path, n_processes, log_name, mode, src_crs, tgt_src)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Reads the gml file and extract features\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39m n_processes) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 81\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgml_to_feather\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43min_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43min_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/temp/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.gml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.feather\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43min_paths\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_crs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_src\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Check for invalid buildings\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(r)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m invalid buildings from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, r)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/multiprocessing/pool.py:372\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/multiprocessing/pool.py?line=365'>366</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstarmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/multiprocessing/pool.py?line=366'>367</a>\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/multiprocessing/pool.py?line=367'>368</a>\u001b[0m \u001b[39m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/multiprocessing/pool.py?line=368'>369</a>\u001b[0m \u001b[39m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/multiprocessing/pool.py?line=369'>370</a>\u001b[0m \u001b[39m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/multiprocessing/pool.py?line=370'>371</a>\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/multiprocessing/pool.py?line=371'>372</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, starmapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/multiprocessing/pool.py?line=763'>764</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/multiprocessing/pool.py?line=764'>765</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/multiprocessing/pool.py?line=765'>766</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/multiprocessing/pool.py?line=766'>767</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/multiprocessing/pool.py?line=760'>761</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/multiprocessing/pool.py?line=761'>762</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/threading.py?line=555'>556</a>\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/threading.py?line=556'>557</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/threading.py?line=557'>558</a>\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/threading.py?line=558'>559</a>\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/threading.py?line=299'>300</a>\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/threading.py?line=300'>301</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/threading.py?line=301'>302</a>\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/threading.py?line=302'>303</a>\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/anaconda3/envs/remote-sensing-landuse/lib/python3.8/threading.py?line=303'>304</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "in_dir = \"data/osaka/udx/bldg\"\n",
    "out_path = \"data/osaka/osaka_full.feather\"\n",
    "\n",
    "batch_gml_to_feather(in_dir, out_path, mode= \"o\", log_name= \"osaka\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 170\n",
      "There are 0 invalid buildings from 170 files\n",
      "Total: 170\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.73</td>\n",
       "      <td>POLYGON ((-8209085.418 5566790.279, -8209067.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.73</td>\n",
       "      <td>POLYGON ((-8209070.390 5566764.459, -8209066.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.38</td>\n",
       "      <td>POLYGON ((-8209005.825 5566671.511, -8208999.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.73</td>\n",
       "      <td>POLYGON ((-8209225.236 5566628.949, -8209213.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.73</td>\n",
       "      <td>POLYGON ((-8209101.448 5566623.003, -8209085.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>4.38</td>\n",
       "      <td>POLYGON ((-8215328.048 5027787.294, -8215324.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>4.74</td>\n",
       "      <td>POLYGON ((-8215264.930 5027796.217, -8215262.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>5.17</td>\n",
       "      <td>POLYGON ((-8215139.829 5027478.327, -8215138.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>5.45</td>\n",
       "      <td>POLYGON ((-8215386.792 5027729.412, -8215384.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>5.71</td>\n",
       "      <td>POLYGON ((-8215318.965 5027747.125, -8215316.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5716439 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       height                                           geometry\n",
       "0        5.73  POLYGON ((-8209085.418 5566790.279, -8209067.0...\n",
       "1        5.73  POLYGON ((-8209070.390 5566764.459, -8209066.2...\n",
       "2        4.38  POLYGON ((-8209005.825 5566671.511, -8208999.0...\n",
       "3        5.73  POLYGON ((-8209225.236 5566628.949, -8209213.3...\n",
       "4        5.73  POLYGON ((-8209101.448 5566623.003, -8209085.8...\n",
       "...       ...                                                ...\n",
       "14994    4.38  POLYGON ((-8215328.048 5027787.294, -8215324.3...\n",
       "14995    4.74  POLYGON ((-8215264.930 5027796.217, -8215262.7...\n",
       "14996    5.17  POLYGON ((-8215139.829 5027478.327, -8215138.1...\n",
       "14997    5.45  POLYGON ((-8215386.792 5027729.412, -8215384.6...\n",
       "14998    5.71  POLYGON ((-8215318.965 5027747.125, -8215316.0...\n",
       "\n",
       "[5716439 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_dir = \"data/NewYork_2\"\n",
    "out_path = \"data/NewYork_2/new_york.feather\"\n",
    "src_crs = \"EPSG:4326\"\n",
    "\n",
    "batch_gml_to_feather(in_dir, out_path, mode= \"o\", log_name= \"new_york\", src_crs= src_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate UMP and export as y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Sentinel and export as X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8bf42f5b4e2a348cbe75a25ff6042248da5e17de0cf2c8b06b72f8092ad4452"
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('remote-sensing-landuse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
